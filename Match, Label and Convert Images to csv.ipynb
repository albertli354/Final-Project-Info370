{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np, PIL, pandas as pd, json, re, pickle, os\n",
    "from hashlib import sha1 as hash_fn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time, localtime, asctime, ctime\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import Markdown, DisplayHandle\n",
    "\n",
    "from stat import S_ISREG, ST_CTIME, ST_MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 20\n",
    "end = 40\n",
    "\n",
    "step_size=20\n",
    "\n",
    "chunk_file_suffix = [i for i in range(start, end, step_size)]\n",
    "\n",
    "base_path = \"../\"\n",
    "\n",
    "data_dir = \"data/intermediate/\"\n",
    "chunking = \"chunking/\"\n",
    "hashes = \"hashes/\"\n",
    "csvs = \"csvs/\"\n",
    "\n",
    "base_mnist_path = base_path+\"mnist/\"\n",
    "by_field_dir = \"by_field/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hash_pickle(filename):\n",
    "    \"\"\"\n",
    "        Read a pickled img hash dictionary, requires filename\n",
    "        returns image hash based dictionary\n",
    "    \"\"\"\n",
    "    file = open(filename, \"rb\")\n",
    "    img_hash_dict = pickle.loads(file.read())\n",
    "    file.close()\n",
    "    return img_hash_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get newest filename\n",
    "def get_newest_pickle():\n",
    "    path = data_dir+hashes\n",
    "\n",
    "    hash_pickles = os.listdir(path)\n",
    "\n",
    "    pickle_stats = {os.stat(path+pickle)[ST_CTIME]:path+pickle for pickle in hash_pickles}\n",
    "    display(pickle_stats)\n",
    "    pickle_key_list = [key for key in pickle_stats.keys()]\n",
    "\n",
    "    pickle_key_list.sort(reverse=True)\n",
    "\n",
    "    pickle_path = None\n",
    "    reloaded = None\n",
    "\n",
    "    start_file = 0\n",
    "\n",
    "    if len(pickle_key_list)>0:\n",
    "        pickle_path = pickle_stats[pickle_key_list[0]]\n",
    "        pickle_name_split = re.split(r\"_([0-9]+)\", pickle_path)\n",
    "        start_file = int(pickle_name_split[-2])\n",
    "\n",
    "    display(Markdown(\"Loading Img Hash Pickle for {} processed files\".format(start_file)))\n",
    "    \n",
    "    if pickle_path is not None:\n",
    "        reloaded = read_hash_pickle(pickle_path)\n",
    "        \n",
    "    return reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1551848557: 'data/intermediate/hashes/by_field_openssl_sha1_Tue_Mar__5_21.01.19_2019_790000.pickle.zip',\n",
       " 1551848627: 'data/intermediate/hashes/by_field_openssl_sha1_Tue_Mar__5_21.03.47_2019_810000.pickle',\n",
       " 1551849413: 'data/intermediate/hashes/by_field_openssl_sha1_Tue_Mar__5_21.16.53_2019_all.pickle',\n",
       " 1551850193: 'data/intermediate/hashes/by_field_openssl_sha1_Tue_Mar__5_21.16.53_2019_all.pickle.zip',\n",
       " 1551852012: 'data/intermediate/hashes/by_field_openssl_sha1_Tue_Mar__5_22.00.12_2019_all.pickle',\n",
       " 1551852031: 'data/intermediate/hashes/by_field_openssl_sha1_Tue_Mar__5_22.00.31_2019_all.pickle',\n",
       " 1551852345: 'data/intermediate/hashes/by_field_openssl_sha1_Tue_Mar__5_22.05.45_2019_all.pickle'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Loading Img Hash Pickle for 2019 processed files"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_hash_dict = get_newest_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash(filename):\n",
    "    \"\"\"\n",
    "        Calc hash of file given a filename\n",
    "        filename: file to hash\n",
    "        returns hexdigest hash\n",
    "    \"\"\"\n",
    "    \n",
    "    from pathlib import Path\n",
    "    \n",
    "    if not Path(filename):\n",
    "        raise ValueError(\"{} does not exist\".format(filename))\n",
    "    \n",
    "    this_hasher = hash_fn()\n",
    "            \n",
    "    with open(filename, \"rb\") as img:\n",
    "        \n",
    "        this_hasher.update(img.read())\n",
    "\n",
    "    img.close()\n",
    "\n",
    "    return this_hasher.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'file_path': '../mnist/by_field/hsf_0/digit/30/30_00000.png',\n",
       " 'char_label': '30'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'file_path': '../mnist/by_field/hsf_0/digit/30/30_00000.png',\n",
       " 'char_label': '30'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "814244"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_file_hash = get_hash(\"../mnist/by_field/hsf_0/digit/30/30_00000.png\")\n",
    "match_file_hash = get_hash(\"../mnist/by_write/hsf_0/f0000_14/d0000_14/d0000_14_00000.png\")\n",
    "\n",
    "display(orig_file_hash == match_file_hash)\n",
    "\n",
    "\n",
    "entry = img_hash_dict[orig_file_hash]\n",
    "display(entry)\n",
    "display(img_hash_dict[match_file_hash])\n",
    "\n",
    "display(Markdown(\"{}\".format(chr(int(entry[\"char_label\"], 16)))))\n",
    "\n",
    "display(len(img_hash_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': '../mnist/by_field/hsf_0/const/57/57_00000.png',\n",
       " 'char_label': '57'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "This is an image of the character with code 0x57 which is \"W\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "by_writer_dir = \"by_write/\"\n",
    "\n",
    "this_hash = hash_fn()\n",
    "\n",
    "with open(base_mnist_path+by_writer_dir+\"hsf_0/f0000_14/c0000_14/c0000_14_00000.png\", \"rb\") as test:    \n",
    "    data = test.read()\n",
    "    this_hash.update(data)\n",
    "    \n",
    "digest = this_hash.hexdigest()\n",
    "    \n",
    "if digest in img_hash_dict.keys():\n",
    "    entry = img_hash_dict[digest]\n",
    "    display(entry)\n",
    "    code = int(entry[\"char_label\"], 16)\n",
    "    display(Markdown(\"This is an image of the character with code 0x{:x} which is \\\"{}\\\"\".format(code, chr(code))))\n",
    "else:\n",
    "    display(\"Test image not found!\")\n",
    "    \n",
    "# if digest in reloaded.keys():\n",
    "#     entry = reloaded[digest]\n",
    "#     display(entry)\n",
    "#     code = int(entry[\"char_label\"], 16)\n",
    "#     display(Markdown(\"This is an image of the character with code 0x{:x} which is \\\"{}\\\"\".format(code, chr(code))))\n",
    "# else:\n",
    "#     display(\"Test image not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Writer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa19849094464d64b389d1136610bcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, max=5.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## File"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43521f07384f4548acc507d5b5e8d17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAADBklEQVR4nO2dwXKDMAwF7U7//5fpgRmGSQIlYGkl+e09xby1ZIcS6MuyNMHxQw9gdiQARgJgJABGAmAkAEYCYCQARgJgJABGAmAkAEYCYCQARgJgJABGAmAkAEYCYCQARgJgJABGAmAkACaEgN57750eBQMvYNroV2AB+/TnrIPufG/olYinul3VScC3U3seByMFjG0giIP9KfgM4HfUH4rcvnvvy7JsI3xJ9mjk66fMxzbqGBYCLo7N1L21A34b+pDIlXeF3AIc0rc+xLA1YDhHtZ99yr8wrAIG9splWSZJv41tQc8dnERPYT0ek53WvXn670jcpr/nJDBZA05OIGwPoSovyiLsf/5Bep3rNvTh9B+7zo/6Uw+JUgED2cIN2+72hBBwfT7uL+nc+HhA/AQczcdv40sd9ztOa0CobhBKYe5rQQXwEBBq+kdDFQADC5j2+9cGKcA0iyx9z1xAliAobAWcpI+0gmj9p+FrgBGJyq6ggETpN1MB0fpPTApWQC4AAZr+e7wFmP+PO1vfsxKQayUEKbUGZLRuIgAJ4vygMftPK1YBR4RNvzkLsAsiY/NZmaICIjNegP9kTNr9V/wqwCiI1Om32i0ofvrNTUCKLBAGC8i7G6EYKSDa8puCxGtA9uV3xUOA7j05IWsFpLvsfIS5gDi/QYtJ1goog62AXN0AIcQvZK7zb/NJp7xUC0qXfgNvTRxOxvRbrgqotPnZSCOgxvfed3IIKDn3VxL8PqDezmdP9AqonX4LLqB8+s3ngU03utCVxxgXSL/FrICpHm88+FLEx4dpXKTwVucE/lrQjdzLTP/mJuD9McC353ul9Fuoh/ZdoVj6LUILuki96Fci7oLeqZp+SyGgcPrN7g0az5eB2rlvWFXAk/gCPsDYDtuXRHxVB/OEvsflLR2fNKzH9XlNSGRmP3+cBLug2kgAjATASACMBMBIAIwEwEgAjATASACMBMBIAIwEwEgAjATASACMBMBIAIwEwEgAjATASACMBMBIAIwEwEgAjATASADMH65+Ee3G5MZOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=128x128 at 0x196AFCD56D8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Adding pandas row... **writer**: 0004 **char_type**:                                        u label: U"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixel_df = pd.DataFrame(columns=[\"label\", \"author_id\", \"char_type\"]+[\"pixel_\"+str(i) for i in range((128**2))])\n",
    "image_df = pd.DataFrame(columns=[\"label\", \"author_id\", \"char_type\", \"image\"])\n",
    "downsample_factor = 1 #start with no downsampling\n",
    "\n",
    "#im = Image.open(file)\n",
    "#ih = IPython.display.Image(data=im)\n",
    "#display(ih)\n",
    "\n",
    "display(Markdown(\"## Writer\"))\n",
    "\n",
    "w_fp = FloatProgress(min=0, max=5)\n",
    "display(w_fp)\n",
    "\n",
    "display(Markdown(\"## File\"))\n",
    "\n",
    "f_fp = FloatProgress(min=0, max=1)\n",
    "display(f_fp)\n",
    "\n",
    "dh_img = DisplayHandle()\n",
    "dh_img.display(Markdown(\"Begin\"))\n",
    "\n",
    "dh_stage = DisplayHandle()\n",
    "dh_stage.display(Markdown(\"Begin\"))\n",
    "\n",
    "index = start-20\n",
    "\n",
    "for suffix in chunk_file_suffix:\n",
    "    dh_stage.update(Markdown(\"Loading Chunk file...\"))\n",
    "    chunk_file = data_dir+chunking+\"all_by_write_files_{}.json\".format(suffix)\n",
    "    \n",
    "    json_file = open(chunk_file)\n",
    "    \n",
    "    chunk_dict = json.loads(json_file.read())\n",
    "\n",
    "    for key, writer_char in chunk_dict.items():\n",
    "        #display(key, writer_char)\n",
    "        f_fp.value = 0\n",
    "        f_fp.max = len(writer_char[\"files\"])\n",
    "        for file in writer_char[\"files\"]:\n",
    "            writer_id = writer_char[\"writer_id\"]\n",
    "            char_type = writer_char[\"char_type\"]\n",
    "            w_fp.value = (int(writer_id)%4)+1\n",
    "            dh_stage.update(Markdown(\"Loading Image file...\\\n",
    "                                        **writer** {} **char_type**: {}\".format(writer_id, char_type)))\n",
    "            #display(file)\n",
    "            \n",
    "            \n",
    "            \n",
    "            digest = get_hash(file)\n",
    "            \n",
    "            dh_stage.update(Markdown(\"Got image file hash...\\\n",
    "                                     **writer** {} **char_type**: {}\".format(writer_id, char_type)))\n",
    "            \n",
    "            code_label = None\n",
    "            \n",
    "            entry = None\n",
    "            try:\n",
    "                entry = img_hash_dict[digest]\n",
    "                #display(entry)\n",
    "                code_label = chr(int(entry[\"char_label\"], 16))\n",
    "                dh_stage.update(Markdown(\"Found matchig image file hash...\\\n",
    "                                            **writer** {} **char_type**: {}\".format(writer_id, char_type)))\n",
    "            except KeyError as e:\n",
    "                display(Markdown(\"hash for {} not found!\".format(file)))\n",
    "                continue\n",
    "\n",
    "            dh_stage.update(Markdown(\"Processing Image file...**writer**: {} **char_type**: {} \\\n",
    "                                        label: {}\".format(writer_id, char_type, code_label)))\n",
    "            \n",
    "            im = Image.open(file)\n",
    "            dh_img.update(im)\n",
    "            \n",
    "            bit2 = im.convert(\"P\", palette=Image.ADAPTIVE, colors=256)\n",
    "            x = int(im.width/downsample_factor)  # 128\n",
    "            y = int(im.height/downsample_factor) # 128\n",
    "            bit2xy = bit2.resize((x, y), resample=PIL.Image.LANCZOS)\n",
    "            \n",
    "            data = bit2xy.getdata()\n",
    "            \n",
    "            #display(len(data))\n",
    "            arr = np.array(data)\n",
    "            \n",
    "            #arr = arr.reshape((x, y))\n",
    "            #plt.imshow(arr)\n",
    "            #plt.show()\n",
    "            dh_stage.update(Markdown(\"Making pandas row... **writer**: {} **char_type**: {}\\\n",
    "                                        label: {}\".format(writer_id, char_type, code_label)))\n",
    "            \n",
    "            row = {\"label\": code_label, \"author_id\":writer_id, \"char_type\": char_type}\n",
    "            \n",
    "            row_w_pixel_cols = {\"pixel_\"+str(index_1d): pixel for index_1d, pixel in enumerate(arr)}\n",
    "            \n",
    "            for k, v in row.items():\n",
    "                row_w_pixel_cols[k] = v\n",
    "            \n",
    "            row[\"image\"] = arr.tolist()\n",
    "            \n",
    "            dh_stage.update(Markdown(\"Adding pandas row... **writer**: {} **char_type**:\\\n",
    "                                        {} label: {}\".format(writer_id, char_type, code_label)))\n",
    "            #df = df.append(row_w_pixel_cols, ignore_index=True)\n",
    "            #df = df.append(row, ignore_index=True)\n",
    "            row_df = pd.DataFrame(data=row_w_pixel_cols, index=[index])\n",
    "            index += 1\n",
    "            pixel_df = pd.concat([pixel_df, row_df], ignore_index=True, sort=False)\n",
    "            image_df = image_df.append(row, ignore_index=True)\n",
    "            #display(df.shape, df.head())\n",
    "            f_fp.value += 1\n",
    "            \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>author_id</th>\n",
       "      <th>char_type</th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_16374</th>\n",
       "      <th>pixel_16375</th>\n",
       "      <th>pixel_16376</th>\n",
       "      <th>pixel_16377</th>\n",
       "      <th>pixel_16378</th>\n",
       "      <th>pixel_16379</th>\n",
       "      <th>pixel_16380</th>\n",
       "      <th>pixel_16381</th>\n",
       "      <th>pixel_16382</th>\n",
       "      <th>pixel_16383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label author_id char_type pixel_0 pixel_1 pixel_2 pixel_3 pixel_4 pixel_5  \\\n",
       "0     W      0000         c       0       0       0       0       0       0   \n",
       "1     e      0000         c       0       0       0       0       0       0   \n",
       "2     t      0000         c       0       0       0       0       0       0   \n",
       "3     h      0000         c       0       0       0       0       0       0   \n",
       "4     e      0000         c       0       0       0       0       0       0   \n",
       "\n",
       "  pixel_6  ... pixel_16374 pixel_16375 pixel_16376 pixel_16377 pixel_16378  \\\n",
       "0       0  ...           0           0           0           0           0   \n",
       "1       0  ...           0           0           0           0           0   \n",
       "2       0  ...           0           0           0           0           0   \n",
       "3       0  ...           0           0           0           0           0   \n",
       "4       0  ...           0           0           0           0           0   \n",
       "\n",
       "  pixel_16379 pixel_16380 pixel_16381 pixel_16382 pixel_16383  \n",
       "0           0           0           0           0           0  \n",
       "1           0           0           0           0           0  \n",
       "2           0           0           0           0           0  \n",
       "3           0           0           0           0           0  \n",
       "4           0           0           0           0           0  \n",
       "\n",
       "[5 rows x 16387 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>author_id</th>\n",
       "      <th>char_type</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>0000</td>\n",
       "      <td>c</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label author_id char_type                                              image\n",
       "0     W      0000         c  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1     e      0000         c  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2     t      0000         c  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3     h      0000         c  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4     e      0000         c  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pixel_df.head())\n",
    "display(image_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold='nan')\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "pixel_df.to_csv(data_dir+csvs+\"mnist_chunks_\"+str(start)+\"_to_\"+str(end)+\"_pixel.csv\", index=False)\n",
    "image_df.to_csv(data_dir+csvs+\"mnist_chunks_\"+str(start)+\"_to_\"+str(end)+\"_image.csv\", index=False)\n",
    "np.set_printoptions(threshold=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_reload_df = pd.read_csv(data_dir+csvs+\"mnist_chunks_\"+str(start)+\"_to_\"+str(end)+\"_pixel.csv\")\n",
    "image_reload_df = pd.read_csv(data_dir+csvs+\"mnist_chunks_\"+str(start)+\"_to_\"+str(end)+\"_image.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
