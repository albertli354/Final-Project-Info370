{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Downloads/output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aab7381e50fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Downloads/output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'output/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Downloads/output'"
     ]
    }
   ],
   "source": [
    "for image in os.listdir('../Downloads/output'):\n",
    "    label = image[:4]\n",
    "    image_path = 'output/' + image\n",
    "    img_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(img_array, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the suitable image size to use, 64 seems reasonable\n",
    "SIZE = 64\n",
    "new_array = cv2.resize(img_array, (SIZE, SIZE))\n",
    "plt.imshow(new_array, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for image in os.listdir('output'):\n",
    "        label = int(image[:4])\n",
    "        image_path = 'output/' + image\n",
    "        img_array = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        new_array = cv2.resize(img_array, (SIZE, SIZE)) # resize\n",
    "        training_data.append([new_array, label])\n",
    "        \n",
    "    \n",
    "    \n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "16\n",
      "28\n",
      "50\n",
      "79\n",
      "3\n",
      "61\n",
      "26\n",
      "71\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# check dataset, all labels are random\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, SIZE, SIZE, 1) \n",
    "X= X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32157 samples, validate on 3574 samples\n",
      "Epoch 1/5\n",
      "32157/32157 [==============================] - 195s 6ms/sample - loss: 4.0784 - accuracy: 0.0674 - val_loss: 3.6236 - val_accuracy: 0.1136\n",
      "Epoch 2/5\n",
      "32157/32157 [==============================] - 173s 5ms/sample - loss: 3.4127 - accuracy: 0.1542 - val_loss: 3.3567 - val_accuracy: 0.1620\n",
      "Epoch 3/5\n",
      "32157/32157 [==============================] - 176s 5ms/sample - loss: 3.1056 - accuracy: 0.2167 - val_loss: 3.2257 - val_accuracy: 0.1919\n",
      "Epoch 4/5\n",
      "32157/32157 [==============================] - 169s 5ms/sample - loss: 2.8650 - accuracy: 0.2658 - val_loss: 3.0909 - val_accuracy: 0.2194\n",
      "Epoch 5/5\n",
      "32157/32157 [==============================] - 169s 5ms/sample - loss: 2.6798 - accuracy: 0.3085 - val_loss: 3.0739 - val_accuracy: 0.2286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1212ce518>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add( Conv2D(64, (3,3), input_shape=X.shape[1:]) )\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "# tf.keras.layers.Dense(100,  activation=tf.nn.softmax)\n",
    "model.add(  Conv2D(64, (3,3)) )\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, validation_split=0.1,epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
